{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"i1qF8cBGH7Gg"},"outputs":[],"source":["import cv2\n","import os\n","from ultralytics import YOLO\n","\n","# Load your fine-tuned YOLOv8 model\n","model = YOLO('your-model-path')\n","\n","# Define the input videos and output paths\n","video_paths = {\n","    'scene-index': 'your-input-video-path',\n","}\n","\n","output_dir = 'your-output-video-path'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Define IoU function\n","def calculate_iou(box1, box2):\n","    x1, y1, x2, y2 = box1\n","    x1_b, y1_b, x2_b, y2_b = box2\n","\n","    xi1, yi1 = max(x1, x1_b), max(y1, y1_b)\n","    xi2, yi2 = min(x2, x2_b), min(y2, y2_b)\n","    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n","\n","    box1_area = (x2 - x1) * (y2 - y1)\n","    box2_area = (x2_b - x1_b) * (y2_b - y1_b)\n","    union_area = box1_area + box2_area - inter_area\n","\n","    iou = inter_area / union_area if union_area > 0 else 0\n","    return iou\n","\n","# Function to perform object tracking and save the output video with counters\n","def track_objects_in_video(video_path, output_video_path):\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        print(f\"Error opening video {video_path}\")\n","        return\n","\n","    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n","    video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), frame_rate, (frame_width, frame_height))\n","\n","    tracks = []  # Initialize object tracks\n","    next_track_id = 1  # Initialize the next track ID\n","\n","    # Object counter variables\n","    class_labels = {0: 'Vehicle', 1: 'Male', 2: 'Female'}  # Map class IDs to labels\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # Reset object counter for this frame\n","        frame_counter = {'Vehicle': 0, 'Male': 0, 'Female': 0}\n","\n","        # Perform object detection using YOLOv8 model\n","        results = model(frame)  # Run inference on the frame\n","\n","        # Extract the bounding boxes, class IDs, and confidence scores\n","        detections = []\n","        for box in results[0].boxes:  # Iterate through detected boxes\n","            x1, y1, x2, y2 = map(int, box.xyxy[0])\n","            cls = int(box.cls[0])\n","            conf = box.conf[0]\n","            detections.append({'bbox': [x1, y1, x2, y2], 'class': cls, 'conf': conf})\n","\n","        # Sort detections by confidence score in descending order\n","        detections = sorted(detections, key=lambda x: x['conf'], reverse=True)\n","\n","        # Keep track of which tracks have been assigned in this frame\n","        assigned_tracks = set()\n","\n","        updated_tracks = []\n","\n","        for detection in detections:\n","            class_id = detection['class']\n","            class_name = class_labels.get(class_id, 'Unknown')\n","\n","            # Update the frame-specific object counter\n","            if class_name in frame_counter:\n","                frame_counter[class_name] += 1\n","\n","            best_iou = 0\n","            best_track_idx = -1\n","            for i, track in enumerate(tracks):\n","                if i in assigned_tracks:\n","                    continue  # Skip already assigned tracks\n","\n","                iou = calculate_iou(detection['bbox'], track['bbox'])\n","                if iou > best_iou and iou > 0.3:  # IoU threshold\n","                    best_iou = iou\n","                    best_track_idx = i\n","\n","            if best_track_idx >= 0:\n","                # Update existing track\n","                tracks[best_track_idx]['bbox'] = detection['bbox']\n","                updated_tracks.append(tracks[best_track_idx])\n","                assigned_tracks.add(best_track_idx)\n","            else:\n","                # Create a new track\n","                new_track = {'id': next_track_id, 'bbox': detection['bbox'], 'class': detection['class']}\n","                updated_tracks.append(new_track)\n","                next_track_id += 1\n","\n","        # Replace old tracks with updated tracks\n","        tracks = updated_tracks\n","\n","        # Draw bounding boxes and track IDs on the frame\n","        for track in tracks:\n","            x1, y1, x2, y2 = track['bbox']\n","            class_name = class_labels.get(track['class'], 'Unknown')\n","            # Draw the object class and ID on the bounding box\n","            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","            cv2.putText(frame, f'ID: {track[\"id\"]} {class_name}', (x1, y1 - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","\n","        # Display object counter on the video\n","        counter_text = f'Vehicles: {frame_counter[\"Vehicle\"]} | Males: {frame_counter[\"Male\"]} | Females: {frame_counter[\"Female\"]}'\n","        cv2.putText(frame, counter_text, (10, frame_height - 20),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n","\n","        # Write the processed frame to the output video\n","        video_writer.write(frame)\n","\n","    # Release resources\n","    cap.release()\n","    video_writer.release()\n","    print(f\"Tracking video saved at {output_video_path}\")\n","\n","# Run object tracking on all videos with object counter\n","for bg_num, video_path in video_paths.items():\n","    output_video_path = os.path.join(output_dir, f'tracked_background_{bg_num}_with_counter.mp4')\n","    track_objects_in_video(video_path, output_video_path)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO2m8jXqz4feZfbnnWcieCi","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
